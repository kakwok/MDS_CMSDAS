{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coffea\n",
    "from coffea.nanoevents.methods import vector\n",
    "import coffea.hist as hist\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import numpy as np\n",
    "import sys,os\n",
    "\n",
    "# from pyjet import cluster\n",
    "import awkward as ak\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema,BaseSchema\n",
    "\n",
    "sys.path.append(os.getcwd().replace('scripts', 'lib'))\n",
    "import util\n",
    "\n",
    "# from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da24a5",
   "metadata": {},
   "source": [
    "# Open data files\n",
    "\n",
    " * First file contains collision data taken with large MET in the trigger in 2016. This is a sub-set of the analysis nTuple that you will use in the rest of the exercise.\n",
    " * The 2nd file contains signal simulation with $H\\rightarrow SS \\rightarrow 4b$ events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49820054",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"/eos/uscms/store/user/cmsdas/2025/long_exercises/MDS/data/displacedJetMuon_ntupler.root\"\n",
    "data = NanoEventsFactory.from_root(fpath,\n",
    "                                   schemaclass=BaseSchema,\n",
    "                                   treepath=\"ntuples/llp\"\n",
    "                                  ).events()\n",
    "\n",
    "fpath =\"/eos/uscms/store/user/cmsdas/2025/long_exercises/MDS/signal/displacedJetMuon_ntupler.root\"\n",
    "\n",
    "signal = NanoEventsFactory.from_root(fpath,\n",
    "                                   schemaclass=BaseSchema,\n",
    "                                   treepath=\"ntuples/llp\"\n",
    "                                  ).events()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c78811",
   "metadata": {},
   "source": [
    "## The tree is loaded with the \"coffea\" analysis framework\n",
    "The events are loaded into an \"awkward arrays\", i.e. arrays with irregular sizes\n",
    "Our event-based data fits into awkward arrays very naturally!\n",
    " - Tree:\n",
    " -  |-muonPt :[ [Pt1,Pt2], [Pt1] ...]\n",
    " -  |-muonEta:[ [Eta1,Eta2], [Eta1] ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618fcbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this awkward array has 16965 events, of the type \"event\"\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2328663",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# shows the branches of the tree\n",
    "data.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c107d",
   "metadata": {},
   "source": [
    "## Accessing a branch like this will give the data in the format of (awkward)arrays\n",
    " - Note that the type becomes \"int32\"\n",
    " - For event-level quantity (number of total rechits),\n",
    "   the length of array is the **same** as the number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89daa770",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ncscRechits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbfeb12",
   "metadata": {},
   "source": [
    " - For object-level quantity (X pos. of each rechit), the first dimension of array is the same as the number of events, but the 2nd dimension of the array is **variable (var, float32)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa56a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cscRechitsX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26546cbb",
   "metadata": {},
   "source": [
    "## Pack all the rechit properties arrays in 1 object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(events,obj_str):\n",
    "    obj  = ak.zip(\n",
    "                {k.replace(obj_str,\"\"):getattr(events,k) for k in events.fields if k.startswith(obj_str)}\n",
    "                ,with_name=\"PtEtaPhiMLorentzVector\",\n",
    "                behavior=vector.behavior\n",
    "               )\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98196f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rechits = pack(data,\"cscRechits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b618bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_rechits = rechits\n",
    "s_rechits = pack(signal,\"cscRechits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01b52c",
   "metadata": {},
   "source": [
    " - These properties mostly follow from the CMSSW definition: [here](https://github.com/cms-sw/cmssw/blob/master/DataFormats/CSCRecHit/interface/CSCRecHit2D.h)\n",
    " - Our nTuplizer only dropped a few properties and computed a few new ones\n",
    " - We will use the following properties:\n",
    "   - Eta,Phi\n",
    "   - X,Y,Z\n",
    "   - Tpeak (Time calculated from strip input), Twire (Time calculated from wire input) [src code](https://github.com/cms-sw/cmssw/blob/master/RecoLocalMuon/CSCRecHitD/src/CSCMake2DRecHit.cc)\n",
    "   - Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b037d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rechits.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d6346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of rechits per event\n",
    "ak.num(rechits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f5573",
   "metadata": {},
   "source": [
    "## Look at the 2D event display of rechits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f157a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayRZ(i_event,rechits=[],cls=[]):\n",
    "    \n",
    "    #Select the rechits in the i-th event\n",
    "    i_rh = rechits[i_event] if len(rechits)>0 else None\n",
    "    i_cls = cls[i_event] if len(cls)>0 else None\n",
    "    \n",
    "    #Make a figure with 2 subplots\n",
    "    fig, axs = plt.subplots(1,2, figsize=(18,8))\n",
    "\n",
    "    axs = axs.flatten()\n",
    "    #plot clusters:\n",
    "    if len(cls)>0:\n",
    "        #Eta-phi plot:        \n",
    "        s1=axs[0].scatter(i_cls.Eta,i_cls.Phi,s=i_cls.Nhit,label=\"Cluster\")\n",
    "        for cl in i_cls:\n",
    "            cone = plt.Circle((cl.Eta, cl.Phi), 0.4, color='b', fill=False,)\n",
    "            axs[0].add_patch(cone)        \n",
    "        \n",
    "        #R-Z plot:        \n",
    "        cls_r = (i_cls.X**2+i_cls.Y**2)**0.5        \n",
    "        axs[1].scatter(np.abs(i_cls.Z),cls_r,s=i_cls.Nhit)            \n",
    "    \n",
    "    #plot rechits:\n",
    "    if len(rechits)>0:\n",
    "        #Eta-phi plot:\n",
    "        s2=axs[0].scatter(i_rh.Eta,i_rh.Phi,s=1,label=\"Rechits\")\n",
    "        rh_r = (i_rh.X**2+i_rh.Y**2)**0.5    \n",
    "        \n",
    "        #R-Z plot:        \n",
    "        axs[1].scatter(np.abs(i_rh.Z),rh_r,s=1)\n",
    "\n",
    "    #label eta-phi plot\n",
    "    axs[0].text(0.1,0.9,\"%s-th event\"%i_event,transform=axs[0].transAxes)\n",
    "    axs[0].set_ylim(-np.pi,np.pi)\n",
    "    axs[0].set_xlim(-5,5)\n",
    "    axs[0].set_ylabel(r\"$\\phi$\")\n",
    "    axs[0].set_xlabel(r\"$\\eta$\")\n",
    "    \n",
    "    #label RZ plot\n",
    "    MB_xmin = 300\n",
    "    util.drawRZ(axs[1],MB_xmin)\n",
    "    axs[1].set_xlim(MB_xmin,None)\n",
    "    axs[1].set_xlabel(\"|z|[cm]\")\n",
    "    axs[1].set_ylabel(\"R[cm]\")\n",
    "    \n",
    "    #make legend\n",
    "    handles, labels = [(a + b) for a, b in zip(axs[0].get_legend_handles_labels(), \n",
    "                                           axs[1].get_legend_handles_labels())]\n",
    "    leg=fig.legend(handles, labels,\n",
    "                   bbox_to_anchor=(1.0, 1.0), loc='upper left')   \n",
    "    for ax in axs:\n",
    "        hep.cms.label(ax=ax,data=True,label=\"Preliminary\")    \n",
    "    for l in leg.legendHandles:\n",
    "        l._sizes = [30]\n",
    "    plt.tight_layout()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daf388f",
   "metadata": {},
   "source": [
    "### Try to look at the rechits from different events!\n",
    "Hint: find an event that has a large number of rechits first to get an interesting event!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400f64a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check which events have large number of rechits\n",
    "np.where(ak.num(rechits)>400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83570913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.CMS) \n",
    "displayRZ(1,rechits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723bf94",
   "metadata": {},
   "source": [
    "# Clustering the rechits\n",
    "\n",
    "### First read the discussion in the lesson: [link](https://kakwok.github.io/MDS_CMSDAS/03-MDS_reco/index.html#clustering-algorithm)\n",
    "\n",
    "### Complete the function `computeCluster`, `computeStationProp` and `computeME11_12`\n",
    "\n",
    "First read the definition of the cluster properties: [here](https://kakwok.github.io/MDS_CMSDAS/03-MDS_reco/index.html#cluster-properties)\n",
    "\n",
    "Then try to implement them in the relevant functions.\n",
    "\n",
    "In particular, \n",
    "\n",
    "### $\\mathrm{avgStation10} = \\frac{\\sum_i (i \\times nhits_i)}{\\sum_i nhits_i}$\n",
    "\n",
    "where `i` sums over the stations with at least 10 hits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f82ffc7",
   "metadata": {},
   "source": [
    "We are using DBSCAN algorithm, implemented with the python lib: `sklearn.cluster`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBScan(rechits,nCore,eps):\n",
    "    points=ak.zip([rechits.Eta,rechits.Phi],highlevel=False)\n",
    "\n",
    "    all_clusters = []\n",
    "    for x,rechit in zip(points,rechits):\n",
    "        n_clusters_=0\n",
    "        core_samples_mask=[]\n",
    "        ## format into DBSCAN input format x=[ [x1,y1],[x2,y2] ... ]        \n",
    "        x=np.stack(ak.unzip(x),axis=1)\n",
    "        i_clusters = []        \n",
    "        if len(x)>0:            \n",
    "            db = DBSCAN(eps=eps, min_samples=nCore).fit(x)\n",
    "            core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "            core_samples_mask[db.core_sample_indices_] = True\n",
    "            labels = db.labels_    \n",
    "            n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "            \n",
    "            ## Loop over clusters in this event\n",
    "            for iCs in range(n_clusters_):\n",
    "\n",
    "                #Compute each cluster's properties:\n",
    "                #    Input = rechits that belongs to this cluster (done via array masking)\n",
    "                cls = computeCluster(rechit[labels==iCs])\n",
    "                i_clusters.append(cls)\n",
    "        all_clusters.append(i_clusters)\n",
    "    return ak.Array(all_clusters)\n",
    "\n",
    "# complete the follwoing function\n",
    "def computeCluster(rechits):\n",
    "    cls = {}\n",
    "\n",
    "    cls[\"Nhit\"] = len(rechits)\n",
    "    cls[\"Eta\"] = \n",
    "    cls[\"Phi\"] = \n",
    "    cls[\"X\"] = \n",
    "    cls[\"Y\"] = \n",
    "    cls[\"Z\"] =         \n",
    "    cls[\"Time\"]= \n",
    "\n",
    "    avgStation10,nStation10 = computeStationProp(rechits)\n",
    "    nME11_12 = computeME11_12(rechits)\n",
    "    \n",
    "    cls[\"nStation10\"] = nStation10\n",
    "    cls['avgStation10'] = avgStation10\n",
    "    cls[\"nME11_12\"] = nME11_12\n",
    "    \n",
    "    return cls\n",
    "\n",
    "# complete the follwoing function by filling the FILL_ME\n",
    "def computeStationProp(rechits):\n",
    "    # station can range from -4 to 4\n",
    "    uniqueStations = np.array([-4,-3,-2,-1,1,2,3,4])    \n",
    "    nStation10   = 0\n",
    "    avgStation10 = 0\n",
    "    TotHitsStation10 = 0\n",
    "    for i_station in uniqueStations:\n",
    "\n",
    "        # total hits in the i-th station e.g. -4 \n",
    "        nRechit_in_i_station = sum(rechits.Station==i_station)\n",
    "        \n",
    "        # \n",
    "        if nRechit_in_i_station >=10:\n",
    "            # number of stations with >=10 hit\n",
    "            nStation10   += FILL_ME\n",
    "            # average of stations position with >=10 hit, weighted by the number of rechits in each station            \n",
    "            avgStation10 += FILL_ME\n",
    "            \n",
    "            # total hits in station with at least 10 hits (i.e. sum of weights of avgStation10)\n",
    "            TotHitsStation10 += nRechit_in_i_station\n",
    "            \n",
    "    avgStation10 = avgStation10/TotHitsStation10\n",
    "    return avgStation10,nStation10\n",
    "\n",
    "def computeME11_12(rechits):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c5875",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "minPoint = 50\n",
    "dR = 0.2\n",
    "cls = DBScan(rechits,minPoint,dR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ad6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c584124d",
   "metadata": {},
   "source": [
    "## Try to see if the cluster in the previous event makes sense!\n",
    "Hint: find an event that has a reconstructed cluster first\n",
    "\n",
    "Do you see a cluster in the event that you chose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb53577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check which events have at least 1 cluster\n",
    "np.where(ak.num(cls)>=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3169c7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "displayRZ(1,rechits,cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd929f2c",
   "metadata": {},
   "source": [
    "# Examine cluster properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2953bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=[\n",
    "    {\"cls\":cls,\"label\":\"data\"},\n",
    "    \n",
    "    # you may add more lines like this one to overlay them on plots\n",
    "    # e.g. {\"cls\":s_cls,\"label\":\"signal\"},       \n",
    "    # where `s_cls` is the clusters from signals \n",
    "]\n",
    "density=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc9a4c",
   "metadata": {},
   "source": [
    "## Number of clusters and N_rechits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.CMS)  \n",
    "fig, axs = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "axs = axs.flatten()\n",
    "h1= hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"nClusters\", \"nClusters\", 10, 0, 10))\n",
    "h2= hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"Nhit\", r\"$N_{rechit}$\", 20, 0, 1000))\n",
    "\n",
    "for sample in samples:\n",
    "    cls = sample['cls']\n",
    "    label = sample['label']\n",
    "    h1.fill(sample=label ,nClusters=ak.num(cls))\n",
    "    h2.fill(sample=label ,Nhit = ak.flatten(cls.Nhit))\n",
    "\n",
    "hist.plot1d(h1,density=density,ax=axs[0])    \n",
    "hist.plot1d(h2,density=density,ax=axs[1])\n",
    "for ax in axs:\n",
    "    \n",
    "    hep.cms.label(ax=ax,data=True,label=\"Preliminary\")        \n",
    "    if density: ax.set_ylabel(\"Density\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec48816",
   "metadata": {},
   "source": [
    "# Eta, Phi distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ae15d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.CMS)  \n",
    "fig, axs = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "axs = axs.flatten()\n",
    "h1= hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"eta\", r\"$\\eta$\", 40, -4, 4))\n",
    "h2= hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"phi\", \"phi\", 64, -3.2, 3.2))\n",
    "\n",
    "for sample in samples:\n",
    "    cls = sample['cls']\n",
    "    label = sample['label']\n",
    "    h1.fill(sample=label ,eta = ak.flatten(cls.Eta))\n",
    "    h2.fill(sample=label ,phi = ak.flatten(cls.Phi))\n",
    "\n",
    "hist.plot1d(h1,density=density,ax=axs[0])    \n",
    "hist.plot1d(h2,density=density,ax=axs[1])\n",
    "for ax in axs:\n",
    "    \n",
    "    hep.cms.label(ax=ax,data=True,label=\"Preliminary\")        \n",
    "    if density: ax.set_ylabel(\"Density\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08eb7a",
   "metadata": {},
   "source": [
    "# R, Z distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2170e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.CMS)  \n",
    "fig, axs = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "axs = axs.flatten()\n",
    "h2 = hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"R\", \"R\", 100, 0, 1000))        \n",
    "h3 = hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"Z\", \"Z\", 120, -1200, 1200))            \n",
    "\n",
    "for sample in samples:\n",
    "    cls = sample['cls']\n",
    "    label = sample['label']\n",
    "    h2.fill(sample=label ,R = ak.flatten((cls.Y**2+cls.X**2)**0.5))\n",
    "    h3.fill(sample=label ,Z = ak.flatten(cls.Z))        \n",
    "\n",
    "hist.plot1d(h2,density=density,ax=axs[0])\n",
    "hist.plot1d(h3,density=density,ax=axs[1])\n",
    "for ax in axs:\n",
    "    \n",
    "    hep.cms.label(ax=ax,data=True,label=\"Preliminary\")        \n",
    "    if density: ax.set_ylabel(\"Density\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882e55e",
   "metadata": {},
   "source": [
    "# Time, nStation10, AvgStation10 distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dca543",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.CMS)  \n",
    "fig, axs = plt.subplots(1,3,figsize=(24,8))\n",
    "\n",
    "axs = axs.flatten()\n",
    "h1= hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"Time\", 'ClusterTime[ns]',50, -100, 100))                        \n",
    "h2= hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"nStation10\", \"Nstation10\", 8, 0, 8))    \n",
    "h3= hist.Hist(\"Events\",hist.Cat(\"sample\",\"sample\"),hist.Bin(\"avgStation10\", \"AvgStation10\", 40, -4, 4))             \n",
    "\n",
    "for sample in samples:\n",
    "    cls = sample['cls']\n",
    "    label = sample['label']\n",
    "    h1.fill(sample=label ,Time = ak.flatten(cls.Time))\n",
    "    h2.fill(sample=label ,nStation10 = ak.flatten(cls.nStation10))\n",
    "    h3.fill(sample=label ,avgStation10 = ak.flatten(cls.avgStation10))    \n",
    "    \n",
    "\n",
    "hist.plot1d(h1,density=density,ax=axs[0])    \n",
    "hist.plot1d(h2,density=density,ax=axs[1])\n",
    "hist.plot1d(h3,density=density,ax=axs[2])\n",
    "for ax in axs:\n",
    "    \n",
    "    hep.cms.label(ax=ax,data=True,label=\"Preliminary\")        \n",
    "    if density: ax.set_ylabel(\"Density\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b393ffd",
   "metadata": {},
   "source": [
    "# Bonus: Cluster ID\n",
    "\n",
    "Some combination of nStation10 and eta may also help us to distinguish between signal and background.\n",
    "\n",
    "We will use these variable to design a \"ClusterID\" later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ec4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h= hist.Hist(\"Events\",\n",
    "              hist.Bin(\"nStation10\", \"Nstation10\", 8, 0, 8),\n",
    "              hist.Bin(\"eta\", r\"$\\eta$\", 40, -3, 3)\n",
    "             )    \n",
    "h.fill(nStation10=ak.flatten(cls.nStation10),\n",
    "      eta = ak.flatten(cls.Eta))\n",
    "h_group = h.group(\"nStation10\",hist.Cat(\"nStationGrp\",\"nStationGrp\"),\n",
    "                 {\n",
    "                     \"nStation=1\":slice(0,2),\n",
    "                     \"nStation>=1\":slice(2,None),                     \n",
    "                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556e734",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.plot1d(h_group,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2cf007",
   "metadata": {},
   "outputs": [],
   "source": [
    "h.to_hist().project(\"eta\",\"nStation10\").plot2d_full()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c2d01",
   "metadata": {},
   "source": [
    "# MDS reconstruction efficiency for signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c4188",
   "metadata": {},
   "source": [
    "When an LLP decay in CSC, we want to know \n",
    " - *how often* it can make an MDS cluster (this is cluster efficiency) and\n",
    " - where does the LLP decay when this happens\n",
    " \n",
    "In this part, we will make a plot of MDS efficiency as a function LLP decay position and try to understand it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123b870",
   "metadata": {},
   "source": [
    "# load a signal ntuple\n",
    "\n",
    "In this ntuple, the DBSCAN algorithm is already performed to reconstruct clusters from rechits, so only clusters and the cluster properties that you've seen in the previous exercise are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath =\"/eos/uscms/store/user/cmsdas/2025/long_exercises/MDS/signal/nocuts/ggH_HToSSTobbbb_MH-125_MS-40_ctau-1000_137000pb_weighted.root\"\n",
    "\n",
    "signal = NanoEventsFactory.from_root(fpath,\n",
    "                                   schemaclass=BaseSchema,\n",
    "                                   treepath=\"MuonSystem\"\n",
    "                                  ).events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b223d3b7",
   "metadata": {},
   "source": [
    "# Selections\n",
    "Here we will select for events that have only one LLP decaying in the CSCs and calculate the probabilty of a cluster being reconstructed given that an LLP decayed in the CSC.\n",
    "You will use the following branches:\n",
    "* `gLLP_csc`: Boolean, a LLP-level variable that tells you whether an LLP decayed in CSC\n",
    "* `gLLP_decay_vertex_z`: LLP-level variable that returns LLP lab frame decay vertex in Z [cm]\n",
    "* `cscRechitCluster_match_gLLP_csc`: Boolean, cluster-level variable that returns true of the cluster is matched to an LLP ($\\Delta R (cluster, LLP) < 0.4$) that decayed in CSC\n",
    "* `cscRechitCluster_match_gLLP_decay_z`: float, cluster-level variable that returns the LLP decay vertex in z if its matched to an LLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6d641",
   "metadata": {},
   "source": [
    "## Ex: Denominator selection\n",
    "\n",
    "We will select events with only 1 LLP decaying in CSC.\n",
    "\n",
    "There are 2 LLPs in each events. \n",
    "\n",
    "Compute the number of LLP that decays in the CSC first, then make a selection mask\n",
    "\n",
    "How many events are there?\n",
    "\n",
    "This will be the denominator of your signal efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "nLLPinCSC = ak.sum(signal.gLLP_csc,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2119531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 2 conditions:\n",
    "# - Only 1 LLP in CSC\n",
    "# - the LLP needs in CSC \n",
    "denom_sel = FILL_ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bbac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Events with 1 LLP decaying in CSC: \", ak.sum(denom_sel))\n",
    "print(\"Total generated signal events \", len(signal))\n",
    "print(\"Acceptance in CSC \", ak.sum(denom_sel)/len(signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff58c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z coordinates of the LLP in the denominator\n",
    "# we sum over the LLPs in the event axis(axis=1) [which there is only 1 LLP]\n",
    "llp_z = ak.sum(abs(signal.gLLP_decay_vertex_z[denom_sel]),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe05f58",
   "metadata": {},
   "source": [
    "## Ex: Numerator selection \n",
    "\n",
    "Select events with only 1 cluster AND in the denominator.\n",
    "\n",
    "Among those events, select the ones that there's one cluster matched to the LLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nClsInCSC = ak.sum(signal.cscRechitCluster_match_gLLP_csc,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb1b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 3 conditions:\n",
    "# - Only 1 cluster in CSC\n",
    "# - Only 1 LLP in CSC\n",
    "# - the cluster needs to be matched to the LLP \n",
    "numer_sel = FILL_ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcd86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z coordinates of the LLP in the numerator\n",
    "# we sum over the clusters in the event axis(axis=1)[which there is only 1 cls]\n",
    "cls_z = ak.sum(abs(signal.cscRechitCluster_match_gLLP_decay_z[numer_sel]),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec64ad",
   "metadata": {},
   "source": [
    "## EX: Inclusive efficiency\n",
    "\n",
    "What is the overall efficiency of reconstructing an MDS cluster of 50 hits for this signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d31613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Events with 1 LLP decaying in CSC: \", FILL_ME)\n",
    "print(\"Events with 1 LLP decaying in CSC and a cluster matched to LLP: \", FILL_ME)\n",
    "print(\"Inclusive efficiency = %.2f\"%(FILL_ME))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049898b",
   "metadata": {},
   "source": [
    "# Fill the histogram \n",
    "\n",
    "This is an **example** of filling a histogram with a `category` axis (for different samples), \n",
    "\n",
    "and a `Bin` axis for storing the values. \n",
    "\n",
    "This is a compact way of handling the histograms. \n",
    "\n",
    "You will use this type of histograms later on in the exercise. \n",
    "\n",
    "Which varaible should we fill-in in the function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a 2D histogram with a \"sample\" axis and an axis\n",
    "hz= hist.Hist(\"Events\",\n",
    "              hist.Cat(\"sample\",\"sample\"), \n",
    "              hist.Bin(\"z\", \"LLP decay Z[cm]\", 35, 400, 1075)\n",
    "             )\n",
    "\n",
    "#Fill the LLP decay position in CSC in the denominator bin\n",
    "hz.fill(sample=\"denom\", z = FILL_ME)\n",
    "#Fill the LLP decay position in CSC matched to a cluster in the numerator bin\n",
    "hz.fill(sample=\"numer\", z = FILL_ME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5e9e2e",
   "metadata": {},
   "source": [
    "# Efficiency v.s. decay position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4c7752",
   "metadata": {},
   "source": [
    "We will plot the cluster reconstruction efficiency with repect to the LLP decay position and overlay the steel region in the plot.\n",
    "\n",
    "Here's a function to draw the CSC steel region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A function to draw the CSC steel region\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def drawCSCz(ax):\n",
    "    ax.set_xlim(350,1150)\n",
    "    (xmin,xmax) = ax.get_xlim()\n",
    "\n",
    "    xmin = 350\n",
    "    y_max = ax.get_ylim()[1]\n",
    "\n",
    "    preME11 = patches.Rectangle((xmin, 0), 568-xmin, 2,color='grey',alpha=0.3)\n",
    "    ME11_12 = patches.Rectangle((632, 0), 39, 2,color='grey',alpha=0.3)\n",
    "    ME12_2  = patches.Rectangle((724, 0), 65, 2,color='grey',alpha=0.3)\n",
    "    ME2_3   = patches.Rectangle((849, 0), 62, 2,color='grey',alpha=0.3)\n",
    "    ME3_4   = patches.Rectangle((970, 0), 32, 2,color='grey',alpha=0.3)\n",
    "    beyond  = patches.Rectangle((1075, 0),150, 2,color='grey',alpha=0.3)\n",
    "\n",
    "    ax.text(570*1.045, y_max*1.02, 'ME1/1', fontsize=16,rotation=90,weight='bold')\n",
    "    ax.text(670*1.02, y_max*1.02, 'ME1/2-3', fontsize=16,rotation=90,weight='bold')\n",
    "    ax.text(800, y_max*1.02, 'ME2', fontsize=16,rotation=90,weight='bold')\n",
    "    ax.text(920, y_max*1.02, 'ME3', fontsize=16,rotation=90,weight='bold')\n",
    "    ax.text(1015, y_max*1.02,'ME4', fontsize=16,rotation=90,weight='bold')\n",
    "    ax.text(xmin+15 ,y_max*0.5, \"Steel\", fontsize=26,rotation=90,weight='bold')\n",
    "    ax.text(xmax-20,y_max*0.5, \"Beyond CMS\", fontsize=26,rotation=90,weight='bold')\n",
    "\n",
    "    ax.add_patch(preME11)\n",
    "    ax.add_patch(ME11_12)\n",
    "    ax.add_patch(ME12_2)\n",
    "    ax.add_patch(ME2_3)\n",
    "    ax.add_patch(ME3_4)\n",
    "    ax.add_patch(beyond)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39258dc0",
   "metadata": {},
   "source": [
    "## Plotting the efficiency \n",
    "\n",
    "We can obtain the 1D histogram by integrating the `numer`/`denom` bin in the 2D histogram.\n",
    "\n",
    "e.g. `hz.integrate(\"sample\",'numer')` will return a 1D histogram with only the numerator content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(hep.style.CMS)  \n",
    "fig, ax = plt.subplots(1,1,figsize=(12,9))\n",
    "\n",
    "# We use the \"clopper-pearson\" \n",
    "# Have a read of what it's doing here (the \"efficiency\" option): \n",
    "# https://hist.readthedocs.io/en/latest/reference/hist.intervals.html#hist.intervals.ratio_uncertainty\n",
    "\n",
    "hist.plotratio(num=hz.integrate(\"sample\",'numer'),\n",
    "               denom=hz.integrate(\"sample\",'denom'),xerr=True,\n",
    "               error_opts={\"linestyle\":'none',\"lw\":4},ax=ax,\n",
    "               unc = \"clopper-pearson\"\n",
    "               )\n",
    "\n",
    "ax.set_ylabel(\"Cluster Efficiency\")\n",
    "ax.set_xlabel(\"LLP z decay position [cm]\")\n",
    "\n",
    "ax=drawCSCz(ax)\n",
    "\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlim(350,1150)\n",
    "ax.grid() \n",
    "hep.cms.label(ax=ax,com=13)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc3397",
   "metadata": {},
   "source": [
    "# Ex: Plot the 2D histogram of LLP and cluster positions\n",
    "\n",
    "- Why does the efficiency drops off at the two ends of the muon detectors?\n",
    "- How does the efficiency varies between the muon stations? Do you understand why?\n",
    "- Make a 2D histogram to confirm your understanding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332d3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "hz= hist.Hist(\"Events\", \n",
    "              hist.Bin(\"z_llp\", \"LLP decay Z[cm]\", 35, 400, 1075),\n",
    "              hist.Bin(\"z_cls\", \"Cluster Z[cm]\", 35, 400, 1075)              \n",
    "             )\n",
    "# Get the LLP decay position in CSC\n",
    "llp_z = FILL_ME\n",
    "# Get the position of the matched cluster in z\n",
    "cls_z = FILL_ME\n",
    "\n",
    "# Fill the 2D \n",
    "hz.fill(z_llp=FILL_ME, z_cls = FILL_ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef15bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 2D histogram\n",
    "hist.plot2d(hz,xaxis=\"z_llp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff14b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
